\section{Numerical experiments}\label{sec:numerical_experiments}
We now analyze the performance of \methodAcronymROMs\ leveraging \spatialAcronym\ trial subspaces on two benchmark problems: the Sod shock tube and compressible flow in a cavity. In each experiment, we compare \methodAcronymROMs\ to the Galerkin and LSPG ROMs. The purpose of the numerical experiments is to assess the impact of minimizing the residual over an arbitrarily sized time window on the solution accuracy. We additionally assess the impact of the time step and time scheme on \methodAcronym. In both experiments, the spatial basis is equivalent for each time window, e.g., $\basisspaceArg{n} \equiv \basisspace$, $n=1,\ldots,\nslabs$. We also note that both experiments are designed to test the \textit{reproductive} ability of the ROMs. We do not consider future state prediction and prediction at new parameter instances as these problems introduce factors that confound the solution accuracy with the solution methodology (e.g., accuracy of the basis). 
 
\subsection{Sod shock tube}
We first consider reduced-order models of the Sod shock tube problem, which is governed by the compressible Euler equations in one dimension, 
\begin{equation}\label{eq:euler_1D}
    \frac{\partial \boldsymbol u}{\partial t} + \frac{\partial \boldsymbol F}{\partial \mathsf{x}} = 0, \quad
    \boldsymbol u= 
    \begin{Bmatrix} \rho \\ \rho u \\ \rho E \end{Bmatrix}, \quad 
    \boldsymbol F = \begin{Bmatrix} \rho u \\ \rho u^2 + p \\  u(\rho E + p) \end{Bmatrix},
\end{equation}
where $\boldsymbol u : \Omega \times [0,T] \rightarrow \RR{3}$ comprise the density, $\mathsf{x}$-momentum, and total energy, $\mathsf{x} \in \Omega \defeq  [0,1]$ is the spatial domain, and 
$T = 1$ the final time. 
The problem setup is given by the initial conditions

\begin{equation*}
\rho = 
\begin{cases} 
      1 & \mathsf{x}\leq 0.5 \\
      0.125 & \mathsf{x} > 0.5 
   \end{cases},
\qquad
p = 
\begin{cases} 
      1 & \mathsf{x}\leq 0.5 \\
      0.1 & \mathsf{x} > 0.5 
   \end{cases},
\qquad
u = 
\begin{cases} 
      0 & \mathsf{x}\leq 0.5 \\
      0 & \mathsf{x} > 0.5 
   \end{cases},
\end{equation*}
along with reflecting boundary conditions at $\mathsf{x}=0$ and $\mathsf{x}=1$. 

\subsubsection{Description of FOM and generation of \spatialAcronym\ trial subspace}\label{sec:sod_fom}
We solve the 1D compressible Euler equations with a finite volume method. We partition the domain into 500 cells of uniform width and employ the Rusanov flux~\cite{rusanov} at the cell interfaces. We employ the Crank--Nicolson (CN) scheme, which is a linear multistep method defined by the coefficients $\alpha_0 = 1,\alpha_1 = -1, \beta_0 = \beta_1 = 1/2$, for temporal integration. We evolve the FOM for $t \in [0.0,1.0]$ at a time-step of $\Delta t = 0.002$. We construct the \spatialAcronym\ trial subspace by executing Algorithm~\ref{alg:pod} with inputs $N_{\text{skip}}=2, \stateIntercept = \bz, K=46 $. The resulting trial subspace corresponds to an energy criterion of $99.99\%$.
%  The solution is saved every other time-step, resulting in 500 solutions snapshots. These snapshots are used to generate a trial basis for the reduced-order models through POD. The trial basis is selected to be of dimension $K = 46$, which corresponds to a $99.99\%$ energy criterion. No affine transformation is used in the construction of the trial subspace, i.e., $\stateIntercept = \bz$.

\subsubsection{Description of reduced-order models}
We consider reduced-order models based on Galerkin projection, LSPG
projection, and the \methodAcronym\ approach. No hyper-reduction is considered 
in this example, i.e., $\stweightingMatArg{n} = \mathbf{I}$, $n=1,\ldots,\nslabs$. Details on the implementation of the 
different reduced-order models is as follows:
\begin{itemize}
\item \textit{Galerkin ROM}: We obtain the Galerkin ROM through Galerkin projection of the FOM and evolve the Galerkin ROM in time with the CN time scheme at a constant time step of $ \Delta t = 0.002$.

\item \textit{LSPG ROM:} We construct the LSPG ROM on top of the FOM
	discretization leveraging the CN time scheme as previously described. Unless
		noted otherwise, we employ a constant time step size of $\Delta t =
		0.002$ for the LSPG ROM. We solve the nonlinear least-squares problem arising at each time instance
		via the Gauss--Newton method, and solve the linear least-squares problems
		arising at each Gauss--Newton iteration via the normal
		equations. We deem the Gauss--Newton iteration converged when the gradient norm is less than $10^{-4}$.  We compute all Jacobians via automatic
		differentiation~\cite{adolc}. 
\item \textit{\methodAcronymROM:} We consider \methodAcronymROMs\ solved via the
	direct and indirect methods with two different solution techniques:
\begin{itemize}
	\item \textit{Direct method}: We consider \methodAcronymROMs\ solved via the direct method for both the same CN discretization employed in the FOM and LSPG, as well as for the second-order explicit Adams Bashforth (AB2) discretization using a constant time step of $\Delta t = 0.0005$. We solve the nonlinear least-squares problem 
arising over each window with the Gauss--Newton method, and solve the linear
		least-squares problems arising at each Gauss--Newton iteration 
		via the normal equations. We again compute all Jacobians via automatic
		differentiation, and deem the Gauss--Newton algorithm converged when
		the gradient norm is less than $10^{-4}$ (i.e., we use the parameter $\epsilon = 10^{-4}$ in Algorithm~\ref{alg:colloc_gn}). Critically, we note that we assemble the (sparse) Jacobian 
matrix over a window by computing local (dense) Jacobians. We store the Jacobian matrix over a window in a compressed sparse row format. We employ uniform quadrature weights for evaluating the integral in~\eqref{eq:obj_gen_slab}. 

\item \textit{Indirect method}: We consider two \methodAcronymROMs\ solved via the indirect method. The first uses the same CN discretization at at time step of $\Delta t = 0.002$, while the second uses the AB2 discretization using a time step of $\Delta t = 0.0005$. We solve the coupled two-point boundary 
problem via the forward--backward sweep method, and compute the action of the Jacobian transpose on vectors via automatic differentiation. We use parameters $\epsilon = 10^{-6}$, $\fbsmGrowth = 1.1$, and $\fbsmDecay=2$ in Algorithm~\ref{alg:st_iter}. 
\end{itemize}
\end{itemize}

%We explore the evaluation of the \methodAcronym\ ROM using both indirect and direct solution methodologies. 
%\subsubsection{Indirect Method}
%The indirect \methodAcronym-ROM solves the coupled boundary value problem using the Forward-Backward Sweep Method (FBSM) described in Section~\ref{sec:fbsm}. A secondd-order collocation method with a time-step size of $\Delta t = 0.002$ and with collocation points placed at the Lobatto points is used for discretization of both the forward and backwards problems. The action of the Jacobian transpose on the residual and adjoint state required for the backwards problem is computed through automatic differentiation~\cite{adolc,pyadolc}. 
%
%\subsubsection{Direct Method}
%The direct \methodAcronym-ROM uses the same second-order collocation method with uniformly distributed collocation points for temporal discretization of both the state 
%and integrand. The resulting least-squares problem is solved using the Gauss-Newton method. The inner Gauss-Newton iterations are solved using the conjugate gradient 
%method preconditioned by the inverse approximate Hessian about the initial guess. 



\subsubsection{Numerical results}
We first assess the impact of the window size on the performance of the \methodAcronymROMs.  We consider a set of \methodAcronymROMs\ that minimize the residual over windows of constant size 
$\DeltaSlabArg{n} \equiv \DeltaSlabArg{} =  .002$, $0.004$ ,$0.008$, $0.02$, $0.04$, $0.10$, $0.20$, $1.0$. We additionally consider the standard Galerkin and LSPG ROMs. We first show results for \methodAcronymROMs\ using the direct method with CN time discretization; a comparison of different time-marching methods and direct/indirect solution techniques will be provided later in this section. 
First, Figure~\ref{fig:sod_density} presents the density solutions produced by the various ROMs at $t = 0.5$ and $1.0$. Figure~\ref{fig:sod_xt} shows 
$x-t$ diagrams for the same density solutions. From Figures~\ref{fig:sod_density} and~\ref{fig:sod_xt}, we observe that the LSPG and Galerkin ROMs accurately characterize 
the system: they correctly track the shock location, expansion waves, etc. We observe both predictions, however, to be highly oscillatory. These oscillations are 
not physical and can lead to numerical instabilities; e.g., due to negative pressure. We observe the \methodAcronymROMs\ to produce less oscillatory solutions than both 
the Galerkin and LSPG ROMs. Critically, we see that the solution becomes less oscillatory as the window size over which the residual is minimized grows. The solution displays no oscillations when the residual is minimized over the entire space--time domain. 

%The impact of the window-size over which the residual is minimized on the ROM solution is first examined. To this end, reduced-order models that minimize the residual over windows of size $\Delta \tau = \Delta t \times [2,5,10,20,50,100,200,1000,2000]$ are considered. Figure~\ref{fig:xtrho} summarizes the performance of the various reduced-order models. Figure~\ref{fig:sod_error_a} shows the integrated $L^2$ state error relative to the Galerkin ROM. Figure~\ref{fig:sod_error_b} shows the space-time residual of the various reduced-order models as measured realitive to the full-order model. In Figure~\ref{fig:sod_error_a}, it is seen that the optimal ROM as measured by the integrated $L^2$ state error occurs at an intermediate window size. This result is perhaps somewhat surprising as one may expect the optimal $L^2$ error to occur when the window size spans the entire temporal domain, in which case the total space-time residual is minimized. As is evident from Figure~\ref{fig:sod_error_a}, however, a lower space-time residual does not necesarily imply a lower error. Figure~\ref{fig:sod_error_b} shows the total integrated space-time residual of the various ROMs as measured with respect to the projected full-order model solution. Increasing the window-size over which the residual is minimized leads to a lower over-all space-time residual. Further, when the residual is minimized over the entire space-time domain ($\Delta \tau =2000$), it is lower than that of the projected full-order model. This numerical evidence supports the theoretical error analysis presented in Section~\ref{sec:error}. In this example, the global space-time residual is lower than that of the projected full-order model for $\Delta \tau > 0.01$.  
%
%Figure~\ref{fig:sod_density} shows density profiles predicted by the CWST-LSPG ROM at two different time instances along with integrated total variation of the solution as measured with respect to the full-order model. It is observed that, as the window size over which the residual is being minimized grows, the solution becomes more smooth. This is measured quantitatively by the total variation of the solution, which decreases monotonically as the window size grows. Next, Figure~\ref{fig:xtrho} shows $x-t$ diagrams for the density variable for the various reduced-order models. It is again seen that, as $\Delta \tau$ grows, the solution becomes more smooth. The increased smoothness comes at the tradeoff that the shock profiles become more smeared. 
%
%Lastly, Figure~\ref{fig:sod_walltime} shows the wall-time of the CWST-LSPG ROM as a function of window-size. The cost is measured with respect to the Galerkin ROM. Two main observations are made. First, the cost of the CWST-LSPG ROM increases as the window size grows. This increased cost is because, as the window size grows, more iterations of the forward and backwards problems are required to converge the solution. While a more sophisticated solution methodology may help mitigate this increased cost, the trends are expected to say the same. The second observation is that the CWST-LSPG ROM is significantly more expensive than the standard Galerkin ROM. As discussed in Section~\ref{sec:implement}, this increased cost is due to the need to iteratively solve the two-point boundary value problem. 
\begin{figure}
\begin{center}
\begin{subfigure}[t]{0.45\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/rho_t05_compare.pdf}
\caption{$t=0.5$}
\end{subfigure}
\begin{subfigure}[t]{0.45\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/rho_t1_compare.pdf}
\caption{$t=1$}
\end{subfigure}
\caption{Density profiles at various time instances.}
\label{fig:sod_density}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\begin{subfigure}[t]{0.48\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/xt_fom.pdf}
\caption{Full-order model}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/xt_grom.pdf}
\caption{G-ROM}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/xt_lspg.pdf}
\caption{LSPG}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/xt_w1.pdf}
\caption{\methodAcronym: $\DeltaSlabArg{}= 0.002$}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/xt_w50.pdf}
\caption{\methodAcronym: $\DeltaSlabArg{} = 0.1$}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/xt_w500.pdf}
\caption{\methodAcronym: $\DeltaSlabArg{} = 1.0$}
\end{subfigure}
\caption{$x-t$ diagrams for the density fields as predicted by the FOM, G-ROM,
	LSPG-ROM, and \methodAcronymROMs. \KTC{Xlabel should be `spatial variable
	$\mathcal x$. Ylabel should be `time $t$'. I wouldn't call this an $x-t$
	diagram; I'd call is a density-solution plot}}
\label{fig:sod_xt}
\end{center}
\end{figure}

Next, Figure~\ref{fig:sod_error} shows space--time state errors and the objective function~\eqref{eq:obj} (i.e., the space--time residual norm) over $t \in [0,1]$ for the various ROMs. Most notably, we observe 
that increasing the window size over which the residual is minimized does \textit{not} lead to a monotonic decrease in the space--time error as measured in the $\elltwo$-norm (we refer to this as the $\elltwo$-error). As expected, increasing the window size does lead to a monotonic decrease in the space--time residual, however. We additionally note that, although the space--time
$\elltwo$-error of 
the projected FOM solution is significantly lower than that of the various ROM solutions, the space--time residual norm of the projected FOM solution is \textit{higher} 
than all ROMs. Thus, although the projected FOM solution is more accurate in the $\elltwo$-norm, it does not satisfy the governing equations as well the ROM solutions. 

\begin{figure}
\begin{center}
\begin{subfigure}[t]{0.45\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/error_vs_window_compare.pdf}
\caption{Space--time $\elltwo$ error of various ROMs.}
\label{fig:sod_error_a}
\end{subfigure}
\begin{subfigure}[t]{0.45\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/objective_vs_window_compare.pdf}
\caption{Integrated residual norm of various ROMs.} 
\label{fig:sod_error_b}
\end{subfigure}
\caption{Integrated performance metrics of the Galerkin, LSPG, and \methodAcronymROMs.  Note that the Galerkin and LSPG ROMs do not depend on the window size.} 
\label{fig:sod_error}
\end{center}
\end{figure}

We now examine the comparative performance of the direct and indirect solution techniques for the \methodAcronymROMs\ using various time discretization techniques. 
Figure~\ref{fig:sod_error_methods} 
shows the same space--time $\elltwo$-errors and residual norms as in Figure~\ref{fig:sod_error}, but this time results are shown for 
the various \methodAcronymROMs. In both Figures~\ref{fig:sod_error_methods_a} and~\ref{fig:sod_error_methods_b}, we observe that the \methodAcronym\ method 
is relatively insensitive to the solution technique (direct vs indirect) and underlying discretization scheme, although some minor differences are observed.
In particular, ROMs using the second order explicit AB2 scheme with a time step of $\Delta t = 0.0005$ provide similar results to the 
ROMs using the second-order CN scheme at a time step of $\Delta t = 0.002$. All methods display similar dependence on the window size: the optimal 
$\elltwo$-error occurs when the window size is $\DeltaSlabArg{} = 0.1$, and the residual decreases monotonically as the window size grows. 
\begin{figure}
\begin{center}
\begin{subfigure}[t]{0.45\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/error_vs_window.pdf}
\caption{Integrated $\elltwo$ error of the \methodAcronymROMs.}
\label{fig:sod_error_methods_a}
\end{subfigure}
\begin{subfigure}[t]{0.45\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/objective_vs_window.pdf}
\caption{Integrated residual norm of the \methodAcronymROMs.} 
\label{fig:sod_error_methods_b}
\end{subfigure}
\caption{Integrated performance metrics of various \methodAcronymROMs.} 
\label{fig:sod_error_methods}
\end{center}
\end{figure}


Next, Figure~\ref{fig:sod_walltime} provides the CPU wall-clock times for the various \methodAcronymROMs. We observe that the computational cost of all methods grows
as the window size is increased. For indirect methods, this increase in cost is due to the fact that, as the window size 
grows, more iterations of the FBSM are required for convergence. For direct methods, the increase in cost is due to (1) the cost 
associated with forming and solving the normal equations at each Gauss--Newton iteration and (2) the increased number of 
Gauss--Newton iterations required for convergence. We observe the cost of the FBSM method to increase more rapidly 
than the direct methods. Encouragingly, \methodAcronymROMs\ based on the CN discretization
minimizing the full space--time residual (comprising 
500 time instances) only  
cost approximately one order of magnitude more than the case where the residual is minimized over a single time step (i.e., LSPG). Also of interest is the 
fact that the direct method utilizing the AB2 time-discretization scheme costs only slightly more per a given window size than the direct method 
utilizing the CN time discretization. This is despite the fact that AB2 is evolved at a time step of $\Delta t = 0.0005$, while CN uses $\Delta t = 0.002$; thus 
AB2 contains 4 times more temporal degrees of freedom than CN.  Finally, we emphasize that the 
results presented here are for standard algorithms (e.g., Gauss--Newton and the FBSM). As mentioned in 
Remarks~\ref{remark:gaussnewton} and~\ref{remark:fbsm}, we expect that the computational cost 
of both indirect and direct methods can be decreased through the use and/or development of 
algorithms tailored to the windowed minimization problem. 


\begin{figure}
\begin{center}
\begin{subfigure}[t]{0.45\textwidth}
%\includegraphics[width=1.\linewidth]{/Users/ejparis/PyROM/pyrom/sod/postProcess_wv/error_vs_window.pdf}
\includegraphics[width=1.\linewidth]{figs/sod/walltime_vs_window.pdf}
\label{fig:sod_error_a}
\end{subfigure}
\caption{Comparison of wall-clock times of the direct and indirect \methodAcronymROMs\ as a function of window size.} 
\label{fig:sod_walltime}
\end{center}
\end{figure}

Finally, we study the impact of the time step on the \methodAcronymROM\ results. We examine \methodAcronymROMs\ that use a
window size of $\Delta T = 0.1$, with time steps $\Delta t =$  $0.001$, $0.002$, $0.005$, $0.01$, $0.05$, $0.1$ (i.e.,  
$100$, $50$, $20$, $10$, $2$, and $1$ time instances per window). We additionally 
consider LSPG ROMs leveraging the same set of time steps. To assess time step convergence, we compare results to a new full-order model, which is as described in Section~\ref{sec:sod_fom} but uses a fine time step of $\Delta t = 10^{-4}$. Figure~\ref{fig:time_step_study} shows the $\elltwo$-error and residual norm  
of the various ROMs. We observe that the $\elltwo$-error and residual norm 
of the \methodAcronymROMs\ decrease and converge as the time step decreases. This is in direct contrast to the LSPG ROMs, in where the $\elltwo$-error and residual norm display a complex dependence on the time step. This result 
demonstrates that \methodAcronym\ overcomes the time-step dependence inherit to the LSPG approach. Lastly, Figure~\ref{fig:walltime_dtvar}
shows the relative wall-clock times of the \methodAcronymROMs\ with respect to the LSPG ROMs. It is seen that for all time steps considered, the \methodAcronymROMs\ 
are less than 6x the cost of LSPG; this is despite the window sizes comprising up to 100 time instances. 
\begin{figure}
\begin{center}
\begin{subfigure}[t]{0.45\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/error_vs_window_dtvar.pdf}
\caption{Space--time $\elltwo$ error of the \methodAcronymROM.}
\label{fig:sod_error_methods_a}
\end{subfigure}
\begin{subfigure}[t]{0.45\textwidth}
\includegraphics[width=1.\linewidth]{figs/sod/objective_vs_window_dtvar.pdf}
\caption{Space--time residual norm of the \methodAcronymROM.} 
\label{fig:sod_error_methods_b}
\end{subfigure}
\caption{Performance metrics of the Galerkin, LSPG, and \methodAcronymROMs.} 
\label{fig:time_step_study}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\begin{subfigure}[t]{0.45\textwidth}
%\includegraphics[width=1.\linewidth]{/Users/ejparis/PyROM/pyrom/sod/postProcess_wv/error_vs_window.pdf}
\includegraphics[width=1.\linewidth]{figs/sod/walltime_vs_window_dtvar.pdf}
\label{fig:sod_error_a}
\end{subfigure}
\caption{Comparison of wall-clock times of the \methodAcronymROMs\ to LSPG ROMs as a function of the time step. WLS ROMs have a fixed window size of $\Delta T = 0.1$.} 
\label{fig:walltime_dtvar}
\end{center}
\end{figure}


\subsubsection{Summary of numerical results for the Sod shock tube}
The key observations from the results of the first numerical example are: 
\begin{enumerate}
\item Increasing the window size over which the residual is minimized led to more physically relevant solutions. Specifically, we observed that as the window size over which the residual was minimized grew, \methodAcronym\ led to less oscillatory solutions.
\item Increasing the window size over which the residual is minimized does not necessary lead to a lower space--time error as measured by the $\elltwo$ norm. We observed that minimizing the residual over an intermediary window size led to the lowest space--time error in the $\elltwo$ norm. 
\item \methodAcronym\ displays time-step convergence: both the space--time $\elltwo$ error and residual norm decreased and displayed time-step convergence as the time step decreased. This is in contrast to LSPG.
\item For all examples considered, in where the windows comprised up to 2000 time instances, \methodAcronym\ with the direct method is between 1x and 10x the cost of the LSPG. The 
direct method was observed to be slightly more efficient and robust than the indirect method.
\end{enumerate} 

\input{cavity}

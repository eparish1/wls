\subsection{\spatialAcronym\ trial spaces}
%\KTC{Make sure that $\trialspace$ and $\stateIntercept$ depend on $n$.}
%\KTC{HERE}
The \spatialAcronym\ trial subspace over the $n$th time window approximates
the FOM ODE solution trajectory $\stateFOM\in\RR{N}\otimes\timeSpace$
with $\approxstateArgnt{n} \in \stspaceSArg{n}$, where
\begin{equation}\label{eq:sttrialspace}
 \stspaceSArg{n} \defeq 
	\trialspaceArg{n} \otimes \timeSpaceArg{n} +
	\stateInterceptArg{n}\otimes\onesFunction^n.
\end{equation}
Here, the spatial trial subspaces $\trialspaceArg{n}\subseteq\RR{\fomdim}$,
$n=1,\ldots,\nslabs$ satisfy 
$\trialspaceArg{n}\defeq\Range{\basismatArg{n}}$ with 
$\basismatArg{n}\equiv[\basisvecArg{n}_1\ \cdots\
\basisvecArg{n}_{\romdimArg{n}}]\in
\RRStar{\romdimArg{n}}{\fomdim}
$ and 
$\onesFunction^n\in\timeSpaceArg{n}$ is defined as
$\onesFunction^n:\timeDummy\mapsto 1.$
% and  
%$\approxstateArgnt{n}: [\timeStartArg{n},\timeEndArg{n}] \rightarrow  \trialspace$ is the \methodAcronym\ approximation to the state over the $n$th time slab.
Thus, at any time instance $t\in[\timeStartArg{n},\timeEndArg{n}]$, the
\spatialAcronym\ trial subspace in this context 
approximates the FOM ODE solution as
\begin{equation}\label{eq:affine_trialspace_tclsrm}
	\stateFOM(t)\approx \approxstateArgnt{n}(t) = \basismatArg{n}
	\genstateArg{n}{t} + \stateInterceptArg{n},
\end{equation}
where $\genstateArgnt{n} \in \RR{\romdim} \otimes \timeSpaceArg{n}$ with
$\genstateArgnt{n}: \timeDummy\mapsto \genstateArgnt{n}(\timeDummy)
$ denotes the generalized coordinates over the $n$th time window. 

Substituting the approximation~\eqref{eq:affine_trialspace_tclsrm} into the
\methodAcronym\ minimization problem~\eqref{eq:tclsrm} implies that the
\methodAcronym\ method with this choice of space--time trial subspace
sequentially computes solutions
$\genstateArgnt{n}$, $n = 1,\ldots,\nslabs$ that satisfy
%For notational purposes, we define the ``decoder", or ``lifting operator",
%that maps the generalized coordinates to the state-space of the full-order
%model as, \begin{align}\label{eq:decoder} \decoder  \vcentcolon & \;
%\genstatey(t) \mapsto \basisspace \genstatey(t) + \stateIntercept, \\
%\vcentcolon & \; \RR{\romdim}  \rightarrow \RR{\fomdim} .  \end{align}
%With $\state(t) \approx \approxstate(t)  =  \decoder(\genstate(t))$, the
%constrained minimization problem at the $n$th time slab can be re-written as,
%The
%constrained minimization problem over the $n$th time slab can be re-written as,

\begin{equation}\label{eq:obj_gen_slab}
\begin{split}
	& \underset{\genstateyArgnt{} \in \RR{\romdimArg{n}} \otimes \timeSpaceArg{n}
			}{\text{minimize}}\; \mathcal{J}^n(\basismatArg{n} \genstateyArgnt{} +
			\stateInterceptArg{n} \otimes \onesFunction^n), \\ 
      & \text{subject to }\; \genstateyArg{}{\timeStartArg{n}} =
	\begin{cases}
\spatialIC & n = 2,\ldots,\nslabs \\
\genstateICOne & n=1. \end{cases} 
\end{split}
\end{equation}
%\begin{equation}\label{eq:obj_gen_slab}
%\begin{split}
%      &\genstateArgnt{n} =   \underset{\genstatey \in \RR{\romdim}}{\text{arg\,min}}\; \mathcal{J}^n(\basisspace \genstatey + \stateIntercept),\\ 
%      &\text{subject to }\; \genstateArg{n}{\timeStartArg{n}} =
%\begin{cases} \genstateArg{n-1}{\timeEndArg{n-1}} & n = 2,\ldots,\nslabs \\
%\genstateIC & n=1, \end{cases} 
%\end{split}
%\end{equation}
%
%Substituting the approximation~\eqref{eq:affine_trialspace_tclsrm} into the minimization problem~\eqref{eq:tclsrm}, the
%constrained minimization problem over the $n$th time slab can be re-written as,
%\begin{equation}\label{eq:obj_gen_slab} \genstate^n =
%\underset{\genstatey}{\text{arg min }} \mathcal{J}^n \bigg( \basisspace
%\genstatey + \stateIntercept \bigg) , \end{equation}
%%\begin{equation}\label{eq:obj_gen_slab} \genstate^n(t) =
%%\underset{\genstatey}{\text{argmin }} \mathcal{J}^n
%%\bigg(\decoder\big(\genstatey(\tau)\big) \bigg) , \end{equation}
%subject to the boundary conditions 
%\begin{equation}\label{eq:bcs}
%\genstate^n(\timeStartArg{n}) = \begin{cases} \genstate^{n-1}(\timeEndArg{n-1}
%) & n = 2,\ldots,\nslabs, \\ \basisspace^T(\stateFOMIC - \stateIntercept) &
%n=1, \end{cases} \end{equation}
%$\genstate^n(\timeStartArg{n}) = \genstate^{n-1}(\timeEndArg{n-1} )$. 
%In the above, $\genstate^n : [\timeStartArg{n} ,
%\timeEndArg{n} ] \rightarrow \RR{\romdim}$ are the generalized coordinates over the $n$th time slab.
We emphasize that problem~\eqref{eq:obj_gen_slab} aims to compute the
\textit{function} $\genstate^n$ that minimizes the \textit{functional}
	$\objectiveArg{n}$. 	%corresponds to
%an infinite dimensional minimization problem: the problem 

\subsubsection{Stationary conditions and the Euler--Lagrange equations}
	\KTC{HERE}
	\KTC{Quite a few issues here. Need to make $\mathcal I$ have a superscript
	$n$ everywhere, including (19), (20), need to replace $[0,T]$ with
	$[t_s^n,t_f^n]$ in the function argumentsi, need to make the functions in
	(19) and (20) depend also on the functional $\hat x^n$ (but use a general
	notation for this variable). Need to make sure all the basis $\basismat$
	have arguments throughout as well as the reference states. }
Stationary conditions for problem~\eqref{eq:obj_gen_slab} can be derived from
	the Euler--Lagrange equations from the
calculus of variations. We begin by defining the
integrand appearing in the objective function $\mathcal{J}^n$ defined in Eq.~\eqref{eq:obj} (in terms of the generalized
coordinates) as 
\begin{equation}\label{eq:integrand}
\begin{split}
 \minintegrandArg{n} & \vcentcolon
(\genstateyDiscreteArgnt{}, \genstateyDiscreteDotArgnt{},\timeDummy) \mapsto \frac{1}{2} \big[
\basisspaceArg{n} \genstateyDiscreteDotArgnt{} - \velocity(\basisspaceArg{n} \genstateyDiscreteArgnt{}
+ \stateIntercept,\timeDummy ) \big]^T \stweightingMatArgt{n}{t} \big[
\basisspaceArg{n} \genstateyDiscreteDotArgnt{}  - \velocity(\basisspaceArg{n} \genstateyDiscreteArgnt{} +
\stateIntercept,\timeDummy) \big], \\ & \vcentcolon \RR{\romdimArg{n}} \times \RR{\romdimArg{n}} \times [\timeStartArg{n},\timeEndArg{n}]
 \rightarrow \RR{} .  
\end{split}
\end{equation}
%$$\minintegrand^n(\genstate^n,\dot{\genstate},t)= \frac{1}{2}
%\big[\frac{\partial \decoder}{\partial \genstate} \dot{\genstate} -
%\velocity(\decoder(\genstate)) \big]^T \stweightingMat(t) \big[\frac{\partial
%\decoder}{\partial \genstate} \dot{\genstate} -
%\velocity(\decoder(\genstate)) \big].$$
We also define the quantities
\begin{equation}
\begin{split}
\dIdVArg{n}  & \vcentcolon
(\genstatey , \genstateyDot, \timeDummy) \mapsto \frac{\partial \minintegrandArg{n}}{\partial \genstateyDiscreteDot} (\genstateyArg{}{\timeDummy}, \genstateyDotArg{}{\timeDummy},\timeDummy), \\ 
& \vcentcolon  \RR{\romdimArg{n}} \otimes \timeSpaceArg{n} \times \RR{\romdimArg{n}} \otimes \timeSpaceArg{n} \times [\timeStartArg{n},\timeEndArg{n}]
 \rightarrow \RR{\romdimArg{n}} ,
\end{split}
\end{equation}
\begin{equation}
\begin{split}
\dIdYArg{n}  & \vcentcolon
(\genstatey , \genstateyDot, \timeDummy) \mapsto \frac{\partial \minintegrandArg{n}}{\partial \genstateyDiscrete} (\genstateyArg{}{\timeDummy}, \genstateyDotArg{}{\timeDummy},\timeDummy), \\ 
& \vcentcolon  \RR{\romdimArg{n}} \otimes \timeSpaceArg{n} \times \RR{\romdimArg{n}} \otimes \timeSpaceArg{n} \times [\timeStartArg{n},\timeEndArg{n}]
 \rightarrow \RR{\romdimArg{n}} .
\end{split}
\end{equation}
Using this notation, the Euler--Lagrange equations (see
Appendix~\ref{appendix:eulerlagrange} for the derivation) over the $n$th
time window are given by, 
\begin{equation}\label{eq:el1} 
\begin{split}
& \dIdYArg{n}(\genstateArg{n}{t},\genstateDotArg{n}{t},t) - \dIdVDotArg{n}(\genstateArg{n}{t},\genstateDotArg{n}{t}, t )  = \bz, \\ 
&\genstate^n(\timeStartArg{n})  = \begin{cases} 
\spatialIC &
n=2,\ldots,\nslabs, \\ 
\genstateICOne & n=1,
\end{cases}\\ 
%&\dIdV (\genstateArg{n}{\timeEndArg{n}},\genstateDotArg{n}{\timeEndArg{n}},\timeEndArg{n}) = \bz.
&\dIdVArg{n}(\genstateArg{n}{\timeEndArg{n}},\genstateDotArg{n}{\timeEndArg{n}},\timeEndArg{n})  = \bz.
\end{split} 
\end{equation}
Evaluating the terms in system~\eqref{eq:el1} is an exercise in
vector calculus, and the step-by-step process is given in
Appendix~\ref{appendix:vector_calc}. The resulting system can be written as the 
coupled forward-backward system for $t \in [\timeStartArg{n},\timeEndArg{n} ]$,
\begin{comment}
The resulting system of equations is
given by the second-order differential equation,
%$$ \bigg[\basisspace^T \bigg[\frac{\partial \velocity}{\partial \state}
%\bigg]^T \stweightingMat  +  \frac{d}{dt} \bigg] \bigg(  \basisspace^T
%\stweightingMat \basisspace \dot{\genstate}   -  \basisspace^T
%\stweightingMat \velocity \bigg) = 0,$$
\EP{Working on this}
\begin{equation}\label{eq:clspg_2ord}
\begin{split} 
&\bigg[\basisspace^T \bigg[\frac{\partial
\velocity}{\partial \stateyDiscreteArgnt{}} (\basisspace \genstateArg{n}{t} +
\stateIntercept,t)\bigg]^T \stweightingMatArgt{n}{t} + \basisspace^T
\stweightingMatArgt{n}{t} \bigg] \bigg(  \basisspace
\genstateDDotArg{n}{t}    -  \velocityDot(\basisspace \genstateArg{n}{t} + \stateIntercept,t) \bigg) = \bz, \qquad t \in  [\timeStartArg{n},\timeEndArg{n}],
\\
&\bigg[\basisspace^T \bigg[\frac{\partial
\velocity}{\partial \stateyDiscreteArgnt{}} (\basisspace \genstateArg{n}{t} +
\stateIntercept,t)\bigg]^T \stweightingMatArgt{n}{t} + \basisspace^T
\stweightingMatArgt{n}{t} \frac{d}{dt} \bigg] \bigg(  \basisspace
\genstateDotArgnt{n}    -  \velocity^*(\basisspace \genstateArgnt{n} + \stateIntercept,t) \bigg) = \bz, \qquad t \in  [\timeStartArg{n},\timeEndArg{n}],
\\
%& \genstateArg{n}{ \timeStartArg{n}} = \genstateArg{n-1}{\timeEndArg{n-1}},
%\\
&\genstate^n( \timeStartArg{n})  = \begin{cases}
\genstate^{n-1}(\timeEndArg{n-1}) & n=2,\ldots,\nslabs, \\
\basisspace^T(\stateFOMIC - \stateIntercept) & n=1, \end{cases}\\ 
& 
\basisspace^T \stweightingMatArgt{n}{\timeEndArg{n}} \basisspace \genstateDotArg{n}{\timeEndArg{n}}  -
\basisspace^T \stweightingMatArgt{n}{\timeEndArg{n}}
\velocity(\basisspace \genstateArg{n}{\timeEndArg{n}} + \stateIntercept,\timeEndArg{n}) = \bz.  
\end{split}
\end{equation}
The second-order system~\eqref{eq:clspg_2ord} can be written equivalently as two first-order
equations by introducing an auxiliary ``\adjointStr", or ``costate", variable. %To do this, first
Defining the costate over the $n$th window as, 
\begin{equation}\label{eq:costate_def}
\begin{split}
\adjointArgnt{n} &: t \mapsto \genstateDotArg{n}{t}  -  \mass^{-1} \basisspace^T \stweightingMatArgt{n}{t}\velocity(\veloargsromn) ,\\
&: [\timeStartArg{n},\timeEndArg{n}] \rightarrow \RR{K} ,
\end{split}
\end{equation}
%\velocity(\veloargsromn)  
%\adjointArg{n}{t}
%\defeq 
%\genstateDotArg{n}{t}  -  \mass^{-1} \basisspace^T \stweightingMatArgt{n}{t}
%\velocity(\veloargsromn) , \end{align}
%\basisspace \frac{d \genstate}{dt}  -   \velocity =  \adjoint  , \qquad
%\genstate(t=0) = \genstate_0 \end{equation}
where
$\massArgnt{n} \equiv \basisspace^T \stweightingMatArgt{n}{t} \basisspace$ is the
mass matrix,
we can manipulate the system~\eqref{eq:clspg_2ord} (see
Appendix~\ref{appendix:vector_calc}) to obtain a coupled forward-backward
system for $t \in  [\timeStartArg{n},\timeEndArg{n}]$,
\end{comment}

\begin{align}\label{eq:lspg_continuous} 
&\massArg{n}   \genstateDotArg{n}{t}  -  [\basisspaceArg{n}]^T
\stweightingMatArgt{n}{t} \velocity(\veloargsromn) =  \massArg{n} \adjointArg{n}{t} , \\
%\end{equation} \begin{equation}\label{eq:lspg_adjoint}
 &\massArg{n}  \adjointDotArg{n}{t}  + [\basisspaceArg{n}]^T \bigg[\frac{\partial
\velocity}{\partial \stateyDiscrete} (\veloargsromn) \bigg]^T \stweightingMatArgt{n}{t} \basisspaceArg{n}
 \adjointArg{n}{t} = \nonumber \\ &-[\basisspaceArg{n}]^T \big[
\frac{\partial \velocity}{\partial \stateyDiscrete}(\veloargsromn) \big]^T \stweightingMatArgt{n}{t} \bigg( \mathbf{I} -
\basisspaceArg{n} [\massArg{n}]^{-1} [\basisspaceArg{n}]^T \stweightingMatArgt{n}{t} \bigg)
 \bigg( \basisspaceArg{n} \genstateDotArg{n}{t} -
\velocity(\veloargsromn) \bigg), \label{eq:lspg_adjoint} \\ &
\genstateArg{n}{\timeStartArg{n}} = \begin{cases}
\spatialIC & n=2,\ldots,\nslabs, \label{eq:lspg_bcs1}\\
\genstateICOne & n=1, \end{cases}\\ &
\adjointArg{n}{\timeEndArg{n}} = \boldsymbol 0, \label{eq:lspg_bcs} 
\end{align}
where 
\begin{equation}\label{eq:costate_def}
\begin{split}
\adjointArgnt{n} &: \timeDummy \mapsto \genstateDotArg{n}{\timeDummy}  -  [\massArg{n}]^{-1} [\basisspaceArg{n}]^T \stweightingMatArgt{n}{\timeDummy}\velocity(\basisspaceArg{n} \genstateArg{n}{\timeDummy} + \stateIntercept , \timeDummy ) ,\\
&: [\timeStartArg{n},\timeEndArg{n}] \rightarrow \RR{\romdimArg{n}} ,
\end{split}
\end{equation}
is the adjoint, or ``costate" variable. 
%where
%$\massArgnt{n}= \basisspace^T \stweightingMatArgt{n}{t} \basisspace$ is the
%mass matrix.
%\end{equation}
Equation~\eqref{eq:lspg_continuous} is equivalent to a Galerkin reduced-order
model forced by the costate variable, $\adjointArgnt{n}$.
Equation~\eqref{eq:lspg_adjoint} is typically referred to as the adjoint
equation, and corresponds to a linear equation that is forced by the residual.
It is worth noting that both~\eqref{eq:lspg_continuous}
and~\eqref{eq:lspg_adjoint} can be hyper-reduced through, e.g.,
collocation, (discrete) empirical interpolation, Gappy POD, etc.~\cite{everson_sirovich_gappy,eim,qdeim_drmac}. The
coupled system defined by~\eqref{eq:lspg_continuous}-\eqref{eq:lspg_bcs} can be interpreted as an ``optimally controlled"
ROM. The adjoint equation controls the forward model by enforcing the minimum
residual condition.
%Note that, $$ \basisspace^T \bigg[\frac{\partial \velocity}{\partial \state}
%\bigg]^T \basisspace \adjoint =  \basisspace^T \bigg[\frac{\partial
%\velocity}{\partial \state} \bigg]^T \stweightingMat \basisspace \adjoint .$$

A simplification is obtained in the basic case %with no
%hyper-reduction/weighting 
where $\stweightingMat = \mathbf{I}$.
The system becomes,
\begin{align*}\label{eq:lspg_continuous_simle} & \genstateDotArg{n}{t}  -
\basisspaceTArg{n}  \velocity(\veloargsromn) =  \adjointArg{n}{t} , \\
%\end{equation} \begin{equation}\label{eq:lspg_adjoint}
 &\adjointDotArg{n}{t}   + \basisspaceTArg{n} \bigg[\frac{\partial
\velocity}{\partial \stateyDiscrete}(\veloargsromn)\bigg]^T \basisspaceArg{n} \adjointArg{n}{t} = \\
&\hspace{2 in} \basisspaceTArg{n} \bigg[
\frac{\partial \velocity}{\partial \stateyDiscrete} (\veloargsromn) \bigg]^T \bigg( \mathbf{I} -   \basisspaceArg{n} \basisspaceTArg{n}
\bigg)    \velocity(\veloargsromn) , \\ & \genstateArg{n}{\timeStartArg{n}} =
\begin{cases} \basisspaceTArg{n}(\basisspaceArg{n-1}\genstateArg{n-1}{\timeEndArg{n-1}} - \stateInterceptArg{n})& n=2,\ldots,\nslabs, \\
\basisspaceTArg{n}(\stateFOMIC - \stateIntercept) & n=1, \end{cases}\\
&\adjointArg{n}{\timeEndArg{n}} = \boldsymbol 0 .  \end{align*}
\begin{remark}
Solutions to the Euler--Lagrange equations correspond to stationary points 
of the objective function~\eqref{eq:obj_gen_slab}. There are no guarantees, 
however, that a stationary point is a minimum. In general, the stationary 
points could be a maximum, a saddle point, a local minimum, etc.
\end{remark}

\subsubsection{Formulation as an optimal control problem of Lagrange type}\label{sec:optimal_control} 
\KTC{Use en-dash for range of numbers like (22)--(25)}
The Euler--Lagrange equations expose that~\eqref{eq:lspg_continuous}--\eqref{eq:lspg_bcs} can be alternatively formulated from as a Lagrange
problem from optimal control. To this end, consider the Galerkin ROM over the $n$th window, 
$$ \basisspaceTArg{n} \stweightingMatArgt{n}{t} \basisspaceArg{n}
 \genstateGalerkinDotArg{n}{t} - \basisspaceTArg{n} \stweightingMatArgt{n}{t}
\velocity(\veloargsromn) = \bz.$$
\KTC{Now that we've defined real-valued functions, just say this for
everything, e.g., $\controllerArgnt{n}\in\RR{\romdim}\otimes\mathcal T^n$.
Also make sure that $\romdim$ is replaced with $\romdimArg{n}$ everywhere.} \EP{Aren't they saying the same thing?} 
 We introduce now the controller $\controllerArgnt{n} :  [\timeStartArg{n},\timeEndArg{n}] \rightarrow
\RR{\romdimArg{n}}$,
and state that a residual minimizing controller exists such that \methodAcronym\ can be written as 
\begin{equation}\label{eq:controlled_rom}
 \basisspaceTArg{n}
\stweightingMatArgt{n}{t} \basisspaceArg{n} \genstateDotArg{n}{t}  - \basisspaceTArg{n}
\stweightingMatArgt{n}{t}\velocity(\veloargsromn) = \controllerArg{n}{t}. 
 \end{equation}
%where $\mass \defeq \big[ \basisspace^T \stweightingMat \basisspace]^{-1} \in
%\RR{\romdim \times \romdim}$ is the \textit{mass matrix}. 
We now demonstrate how to find this controller.
Before doing so, it is noted that~\eqref{eq:controlled_rom} displays commonalities with \textit{subgrid-scale}
methods~\cite{iliescu_pod_eddyviscosity,iliescu_vms_pod_ns,iliescu_ciazzo_residual_rom,parish_apg,wentland_apg,Wang:269133,San2018},
in where an additional term is added to the reduced-order model so-as to
account for the truncated dynamics. 

We start by defining a \textit{Lagrangian} that measures the residual norm as a function of the state and controller, 
\begin{equation}\label{eq:obj_controller}
\begin{split}
%\objectiveControlArg{n}(\stateArg{}{t}) = \frac{1}{2}
%\int_{\timeStartArg{n}}^{\timeEndArg{n}} \big[ \basisspace
%\dot{\genstate}(\tau) - \velocity(\stateArg{}{\tau} ) \big]^T
%\stweightingMat(\tau) \big[ \dot{\state}(\tau) - \velocity(\stateArg{}{\tau})
%\big] d \tau, \objectiveControlArg{n}(\genstateArg{}{t},\controllerArg{}{t})
%= \\ \frac{1}{2} \bigg[ \basisspace \bigg(  \mass^{-1}\basisspace^T
%\stweightingMat\velocity(\basisspace \genstate) + \mass^{-1}\controller
%\bigg) - \velocity(\basisspace \genstate ) \bigg]^T \stweightingMat(t) \bigg[
%\basisspace \bigg(  \mass^{-1}\basisspace^T
%\stweightingMat\velocity(\basisspace \genstate) + \mass^{-1}\controller
%\bigg) - \velocity( \basisspace  \genstate ) \bigg] , \\
 \objectiveControlArg{n} &:  (\genstateyDiscreteArgnt{},\controllerDiscreteDumArgnt{},\timeDummy)
\mapsto \frac{1}{2} \bigg[ \basisspaceArg{n} \bigg(  [\massArg{n}]^{-1}\basisspaceTArg{n}
\stweightingMatArgt{n}{t}  \velocity(\basisspaceArg{n} \genstateyDiscreteArgnt{} +
\stateInterceptArg{n},\timeDummy) + [\massArg{n}]^{-1}\controllerDiscreteDumArgnt{} \bigg) -
\velocity(\basisspaceArg{n} \genstateyDiscreteArgnt{} + \stateInterceptArg{n},\timeDummy) \bigg]^T
\stweightingMatArgt{n}{t}  \\ & \hspace{1.5 in}\bigg[ \basisspace \bigg(
[\massArg{n}]^{-1}\basisspaceTArg{n} \stweightingMatArgt{n}{t}\velocity(\basisspaceArg{n}
\genstateyDiscreteArgnt{} + \stateIntercept,\timeDummy) + [\massArg{n}]^{-1}\controllerDiscreteDumArgnt{}
\bigg) - \velocity( \basisspaceArg{n}  \genstateyDiscreteArgnt{} + \stateInterceptArg{n},\timeDummy ) \bigg]
, \nonumber \\ & : \RR{\romdimArg{n}} \times \RR{\romdimArg{n}} \times [\timeStartArg{n},\timeEndArg{n}] \rightarrow \RR{},
 %\int_{\timeStartArg{n}}^{\timeEndArg{n}}
 %\objectiveControlArg{n}(\genstateArg{}{\tau},\controllerArg{}{\tau}) d\tau =
 %\\ \frac{1}{2} \int_{\timeStartArg{n}}^{\timeEndArg{n}} \bigg[ \basisspace
 %\bigg(  \mass^{-1}\basisspace^T \stweightingMat\velocity(\basisspace
 %\genstate) + \mass^{-1}\controller \bigg) - \velocity(\basisspace \genstate
 %) \bigg]^T \stweightingMat(\tau) \bigg[ \basisspace \bigg(
 %\mass^{-1}\basisspace^T \stweightingMat\velocity(\basisspace \genstate) +
 %\mass^{-1}\controller \bigg) - \velocity( \basisspace  \genstate ) \bigg] d
 %\tau,
\end{split}
\end{equation}
where it is noted that, by~\eqref{eq:controlled_rom}, $
[\massArg{n}]^{-1}\basisspaceTArg{n} \stweightingMatArg{n} \velocity(\basisspaceArg{n} \genstateArg{n}{t} + \stateInterceptArg{n} ,t) +
[\massArg{n}]^{-1}\controllerArg{n}{t}  = \genstateDotArg{n}{t}.$ 
Hence~\eqref{eq:obj_controller} is a measure of the same residual as in~\eqref{eq:obj}.  The \methodAcronym\ method can be formulated as a minimization problem 
that computes the controller $\controllerArgnt{n}$, for $n=1,\ldots,\nslabs$, as the solution to the minimization problem, 
\begin{equation}\label{eq:tclspg_oc1a} 
\begin{split}
&\underset{\controllerDumArgnt{n} }{\text{minimize } } 
\int_{\timeStartArg{n}}^{\timeEndArg{n}}
\objectiveControlArg{n}(\genstateArg{n}{t},\controllerDumArg{n}{t},t)dt, 
 \\
&\text{subject to } \;  \left\{\begin{array}{l} 
 \basisspaceTArg{n} \stweightingMatArgt{n}{t}
\basisspaceArg{n}  \genstateDotArg{n}{t}  - \basisspaceArg{n}
\stweightingMatArgt{n}{t} \velocity(\veloargsromn) =\controllerDumArg{n}{t}, \\
 \genstateArg{n}{\timeStartArg{n}} =
\begin{cases} \basisspaceTArg{n}(\basisspaceArg{n-1}\genstate^{n-1}(\timeEndArg{n-1} ) - \stateInterceptArg{n} )& n = 2,\ldots,\nslabs,
 \\ \basisspaceTArg{n}(\stateFOMIC - \stateIntercept) & n=1. \end{cases} \end{array} \right.
% \genstateArg{n-1}{\timeEndArg{n-1}}.
\end{split}
\end{equation}
%\begin{equation}\label{eq:tclspg_oc1a} 
%\begin{split}
%&\controllerArgnt{n} =
%\underset{\controllerDumArgnt{} }{\text{arg\,min } } 
%\int_{\timeStartArg{n}}^{\timeEndArg{n}}
%\objectiveControlArg{}(\genstateArg{n}{t},\controllerDumArg{}{t},t)dt, 
% \\
%&\text{subject to } \;  \left\{\begin{array}{l} 
% \basisspace^T \stweightingMatArgt{n}{t}
%\basisspace \frac{d}{dt} \genstateArg{n}{t}  - \basisspace^T
%\stweightingMatArgt{n}{t} \velocity(\basisspace \genstateArg{n}{t} +
%\stateIntercept,t) =\controllerArg{n}{t}, \\
% \genstateArg{n}{\timeStartArg{n}} =
%\begin{cases} \genstate^{n-1}(\timeEndArg{n-1} ) & n = 2,\ldots,\nslabs,
% \\ \basisspace^T(\stateFOMIC - \stateIntercept) & n=1. \end{cases} \end{array} \right.
%% \genstateArg{n-1}{\timeEndArg{n-1}}.
%\end{split}
%\end{equation}
%Noting that
%$$\basisspace^T \stweightingMat \basisspace \dot{\genstate} = \basisspace^T \controller + \basisspace^T \stweightingMat \velocity(\basisspace \genstate).$$
%$$\basisspace \dot{\genstate} =  \basisspace \controller + \basisspace \basisspace^T \velocity(\basisspace \genstate).$$
%Then
%\begin{equation}\label{eq:obj}
%\objectiveControlArg{n}(\stateArg{}{t}) = \frac{1}{2} \int_{\timeStartArg{n}}^{\timeEndArg{n}} \big[\basisspace \controller + (\basisspace \basisspace^T  - \mathbf{I} )\velocity(\basisspace \genstate)   ) \big]^T \stweightingMat(\tau) \big[\basisspace \controller + (\basisspace \basisspace^T - \mathbf{I}) \velocity(\stateArg{}{\tau})  \big] d \tau,
%\end{equation}
The solution to the system~\eqref{eq:tclspg_oc1a} is equivalent of that defined by~\eqref{eq:obj_gen_slab}. 
This can be demonstrated via the \textit{Pontryagin Maximum Principle} (PMP)~\cite{optimal_control_book}. To this end, we introduce the Lagrange multiplier (costate) 
$\adjointOCArgnt{n}: [\timeStartArg{n},\timeEndArg{n}] \mapsto \RR{\romdim}$ and define the Hamiltonian, 
\begin{equation}\label{eq:hamiltonian}
\begin{split}
\hamiltonianArg{n} \; &: \;  (\genstateyDiscreteArgnt{},\adjointDiscreteDumArgnt{},\controllerDiscreteDumArgnt{},\timeDummy) \mapsto 
 \adjointDiscreteDumArgnt{T} \bigg[  [\massArg{n}]^{-1}\basisspaceTArg{n} \stweightingMatArgt{n}{t}\velocity(\basisspaceArg{n} \genstateyDiscreteArgnt{} + \stateInterceptArg{n},\timeDummy) + [\massArg{n}]^{-1}\controllerDiscreteDumArgnt{} \bigg] +  \objectiveControlArg{}(\genstateyDiscreteArgnt{},\controllerDiscreteDumArgnt{},\timeDummy) \\
&: \; \RR{\romdimArg{n}} \times \RR{\romdimArg{n}} \times \RR{\romdimArg{n}} \times [\timeStartArg{n},\timeEndArg{n}] \rightarrow \RR{}.
\end{split}
\end{equation} 
The Pontryagin Maximum Principle states that, for a trajectory to be an extremal of~\eqref{eq:tclspg_oc1a} (with the dynamics constraints), it must satisfy the 
following conditions over the $n$th window,
\begin{align*}%\label{eq:hamiltonian_sys}
&\genstateDotArg{n}{t} = \frac{\partial \hamiltonianArg{n}}{\partial \adjointDiscreteDumArgnt{}{}}(\genstateArg{n}{t},\adjointOCArg{n}{t},\controllerArg{n}{t},t),\\% \qquad \genstate(t_0(n)) = \genstate^{n-1}(t_1(n-1))\\
&\adjointOCDotArg{n}{t}= - \frac{\partial \hamiltonianArg{n}}{\partial \genstateyDiscreteArgnt{}{}}(\genstateArg{n}{t},\adjointOCArg{n}{t},\controllerArg{n}{t},t),\\% \qquad \adjoint^n(t_1(n)) = 0\\
&\frac{\partial \hamiltonianArg{n}}{\partial \controllerDiscreteDumArgnt{}{}} (\genstateArg{n}{t},\adjointOCArg{n}{t},\controllerArg{n}{t},t) = \boldsymbol 0, \\
& \genstateArg{n}{\timeStartArg{n}} =
\begin{cases} \spatialIC & n = 2,\ldots,\nslabs,
 \\ \genstateIC & n=1,\end{cases} \\
&\adjointOCArg{n}{\timeEndArg{n}}= \bz.
\end{align*}
Evaluation of the required gradients (Appendix~\ref{appendix:optimal_control}) yields the system to be solved over the $n$th window for $t \in [\timeStartArg{n},\timeEndArg{n}]$,
\begin{align}\label{eq:sys_oc1}
&\massArg{n}  \genstateDotArg{n}{t}  -  \basisspaceTArg{n} \stweightingMatArgt{n}{t} \velocity(\veloargsromn) =  \controllerArg{n}{t} , \\
%\end{equation}
%\begin{equation}\label{eq:lspg_adjoint}
 & \adjointOCDotArg{n}{t}  + \basisspaceTArg{n} \bigg[\frac{\partial \velocity}{\partial \stateyDiscrete} (\veloargsromn) \bigg]^T \stweightingMatArgt{n}{t} \basisspaceArg{n} [\massArg{n}]^{-1} \adjointOCArg{n}{t} = \nonumber \\
 & \qquad \basisspaceTArg{n} \big[ \frac{\partial \velocity}{\partial \stateyDiscrete}(\veloargsromn) \big]^T \stweightingMatArgt{n}{t} \bigg( \mathbf{I} -   \basisspaceArg{n} [\massArg{n}]^{-1} \basisspaceTArg{n}  \stweightingMatArgt{n}{t} \bigg)  \bigg( \basisspaceArg{n}\genstateDotArg{n}{t}  -   \velocity(\veloargsromn) \bigg) \label{eq:sys_oc2} \\
&\controllerArg{n}{t} = -\adjointOCArg{n}{t} \label{eq:sys_oc3}, \\
& \genstateArg{n}{\timeStartArg{n}} = 
\begin{cases}
\spatialIC& n=2,\ldots,\nslabs, \\
\genstateIC & n=1,  
\end{cases} \label{eq:sys_oc4} \\
& \adjointOCArg{n}{\timeEndArg{n}} = \boldsymbol 0 \label{eq:sys_oc5}.
\end{align}
The system defined by~\eqref{eq:sys_oc1}-\eqref{eq:sys_oc5} is seen to be equivalent to that defined by~\eqref{eq:lspg_continuous}-\eqref{eq:lspg_bcs} (perform 
the change of variables $\controllerArgnt{n} = \massArg{n} \adjointArgnt{n}$ in~\eqref{eq:sys_oc1} and $\adjointOCArgnt{n} = -\massArg{n} \adjointArgnt{n}$ in~\eqref{eq:sys_oc2}). 
Thus, \methodAcronym\ with \spatialAcronym\ trial subspaces be formulated as an optimal control problem: \methodAcronym\ finds a controller that modifies the Galerkin ROM such that the residual minimization objective is achieved. In addition to commonalities with optimal control problems, this second formulation displays commonalities with subgrid-scale modeling techniques, in where an additional term is added to the reduced-order model to account for the impact of the truncated modes. \methodAcronym\ can thus be interpreted as a subgrid-scale modeling technique, in where a residual minimizing subgrid-scale model is constructed.

\begin{remark}
The Euler--Lagrange equations comprise a Hamiltonian system. This imbues \methodAcronym\ with certain properties; e.g., for autonomous systems the Hamiltonian~\eqref{eq:hamiltonian} is conserved. 
\end{remark} 

